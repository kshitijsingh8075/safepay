python
Copy
import os
import re
import pandas as pd
import numpy as np
from flask import Flask, request, jsonify, escape
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_extraction import FeatureHasher
from sklearn.base import BaseEstimator, TransformerMixin
from flask_limiter import Limiter
import joblib
import requests

app = Flask(__name__)
limiter = Limiter(app, default_limits=["100 per hour"]) # Rate limiting

# Security: Allow only UPI-like patterns
VALID_UPI_REGEX = r'^[a-zA-Z0-9.\-]{3,256}@[a-zA-Z]{3,64}$'

class FeatureEngineer(BaseEstimator, TransformerMixin):
"""Advanced feature engineering pipeline"""
def __init__(self):
self.url_keywords = ["login", "verify", "phish", "scam"]
self.hasher = FeatureHasher(n_features=10, input_type='string')

def transform(self, X, y=None):
features = []
for vpa, amt, raw_text in zip(X['bene_vpa'], X['amount'], X['raw_text']):
# Domain analysis
domain = vpa.split('@')[-1] if '@' in vpa else ''
hashed = self.hasher.transform([[domain]]).toarray()[0]

# URL heuristics
is_shortened = 1 if re.search(r"(bit\.ly|goo\.gl)", raw_text) else 0
has_suspicious_keyword = 1 if any(kw in raw_text.lower() for kw in self.url_keywords) else 0

# UPI syntax checks
syntax_valid = 1 if re.match(VALID_UPI_REGEX, vpa) else 0
special_chars = len(re.findall(r'[%&#=]', vpa))

# Temporal features (mock - integrate real data)
recent_frequency = 0 # Would come from user's transaction history

feature_vec = np.concatenate([
[amt, is_shortened, has_suspicious_keyword, syntax_valid, special_chars, recent_frequency],
hashed
])
features.append(feature_vec)

return np.array(features)

# Load pre-trained model and feature engineer
model = joblib.load('scam_model.pkl')
fe = joblib.load('feature_engineer.pkl')

def check_live_threats(text):
"""Query PhishTank and Google Safe Browsing"""
phish_result = requests.post(
'https://checkurl.phishtank.com/checkurl/',
data={'url': text, 'format': 'json'},
headers={'User-Agent': 'Safe-Pay/1.0'}
).json()

safe_browsing = requests.post(
'https://safebrowsing.googleapis.com/v4/threatMatches:find?key=YOUR_KEY',
json={
"client": {"clientId": "safepay", "clientVersion": "1.0"},
"threatInfo": {
"threatTypes": ["MALWARE", "SOCIAL_ENGINEERING"],
"platformTypes": ["ANY_PLATFORM"],
"threatEntryTypes": ["URL"],
"threatEntries": [{"url": text}]
}
}
).json()

return phish_result.get('in_database') or safe_browsing.get('matches')

@app.route('/predict', methods=['POST'])
@limiter.limit("10/minute") # Anti-DDoS
def predict():
try:
data = request.json
raw_text = escape(data.get('raw_text', ''))
bene_vpa = escape(data.get('bene_vpa', ''))
amount = float(data.get('amount', 0))

# Rule-Based First Layer
if check_live_threats(raw_text):
return jsonify({'label': 'Scam', 'reason': 'Known malicious pattern'})

if not re.match(VALID_UPI_REGEX, bene_vpa):
return jsonify({'label': 'Scam', 'reason': 'Invalid UPI syntax'})

# Feature Engineering
X = pd.DataFrame([{
'bene_vpa': bene_vpa,
'amount': amount,
'raw_text': raw_text
}])

features = fe.transform(X)

# ML Prediction
proba = model.predict_proba(features)[0][1]
if proba > 0.65: # Tuned threshold
return jsonify({
'label': 'Scam',
'probability': float(proba),
'reason': 'ML model detected suspicious patterns'
})

return jsonify({'label': 'Safe', 'probability': float(proba)})

except Exception as e:
app.logger.error(f"Prediction error: {str(e)}")
return jsonify({'error': 'Security check failed'}), 400

if __name__ == "__main__":
app.run(host='0.0.0.0', port=8080)
Key Improvements:
Hybrid Detection System

Rule-Based First Layer:

Immediate blocking of known phishing URLs via PhishTank/Google Safe Browsing

UPI syntax validation using regex (VALID_UPI_REGEX)

ML Second Layer:

Uses feature hashing for unseen domains

Advanced features: URL shortening, special chars, temporal patterns

Security Enhancements

Input sanitization with escape()

Rate limiting (10 requests/min)

Regex whitelisting for UPI IDs

Feature Engineering

python
Copy
[
amount,
is_shortened_url,
has_suspicious_keyword,
upi_syntax_valid,
special_char_count,
transaction_frequency,
*hashed_domain_features # 10 dimensions
]
Production-Ready

Proper error logging

Separate feature engineering pipeline

Tuned decision threshold (0.65)

Frontend Integration Update:
javascript
Copy
async function checkQrForScam(qrData) {
try {
const res = await fetch('/predict', {
method: 'POST',
headers: {'Content-Type': 'application/json'},
body: JSON.stringify({
raw_text: qrData, // Pass entire QR content
bene_vpa: extractVPA(qrData), // Your UPI extraction logic
amount: extractAmount(qrData)
})
});

const result = await res.json();

if(result.label === 'Scam') {
showRedAlert(`Blocked: ${result.reason} (${(result.probability*100).toFixed(1)}% risk)`);
logToAnalytics(qrData); // For retraining
} else {
showGreenCheckmark(`Safe: ${(result.probability*100).toFixed(1)}% confidence`);
}
} catch(error) {
showWarning("Security check unavailable - proceed with caution");
}
}
To Deploy:
Required APIs:

Sign up for PhishTank API

Enable Google Safe Browsing API

Retraining Pipeline:

bash
Copy
# Add this to .replit
run = "python retrain.py && python main.py"

# retrain.py
import daily from new fraud reports
model.partial_fit(new_data) # Online learning